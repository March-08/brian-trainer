{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from kor.extraction import create_extraction_chain\n",
    "from kor.nodes import Object, Text\n",
    "from kor import create_extraction_chain\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prollo/miniforge3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "##llm = OpenAI(temperature=0.9)\n",
    "from langchain import HuggingFaceHub\n",
    "\n",
    "repo_id = \"google/flan-t5-small\" # See https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads for some other options\n",
    "repo_id = \"tiiuae/falcon-7b\"\n",
    "llm = HuggingFaceHub(repo_id=repo_id, model_kwargs={\"temperature\":0, \"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceHub(cache=None, verbose=False, callbacks=None, callback_manager=None, client=InferenceAPI(api_url='https://api-inference.huggingface.co/pipeline/text-generation/tiiuae/falcon-7b', task='text-generation', options={'wait_for_model': True, 'use_gpu': False}), repo_id='tiiuae/falcon-7b', task=None, model_kwargs={'temperature': 0, 'max_length': 64}, huggingfacehub_api_token=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "examples = [\n",
    "  {\n",
    "    \"question\": \"I want to know the wstETH balance of 0xFe8e15ae884524eFfc2fe91dF6f5BA40D8533A92 on Gnosis\",\n",
    "    \"answer\": \"action:balance,token:wstETH,address:0xFe8e15ae884524eFfc2fe91dF6f5BA40D8533A92,chain:Gnosis,amount:100\"\n",
    "  },\n",
    "  {\n",
    "    \"question\":\"I want to swap 100 XDAI for DAI on Gnosis\",\n",
    "    \"answer\":\"action:swap,token1:XDAI,token2:DAI,chain:Gnosis,amount:100\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"I want to send or transfer 100 WETH to 0xFe8e15ae884524eFfc2fe91dF6f5BA40D8533A92 on Gnosis\",\n",
    "    \"answer\":\"action:transfer,token:WETH,chain:Gnosis,address:0xFe8e15ae884524eFfc2fe91dF6f5BA40D8533A92,amount:100\"\n",
    "  },\n",
    "  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: I want to know the wstETH balance of 0xFe8e15ae884524eFfc2fe91dF6f5BA40D8533A92 on Gnosis\n",
      "action:balance,token:wstETH,address:0xFe8e15ae884524eFfc2fe91dF6f5BA40D8533A92,chain:Gnosis,amount:100\n"
     ]
    }
   ],
   "source": [
    "example_prompt = PromptTemplate(input_variables=[\"question\", \"answer\"], template=\"Question: {question}\\n{answer}\")\n",
    "\n",
    "print(example_prompt.format(**examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate(input_variables=[\"question\", \"answer\"], template=\"Question: {question}\\n{answer}\")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples, \n",
    "    example_prompt=example_prompt, \n",
    "    suffix=\"Question: {input}\", \n",
    "    input_variables=[\"input\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FewShotPromptTemplate' object has no attribute 'predict_and_parse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(prompt\u001b[39m.\u001b[39;49mpredict_and_parse(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mI want to swap 100 DAI to USDC on UniSwap\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FewShotPromptTemplate' object has no attribute 'predict_and_parse'"
     ]
    }
   ],
   "source": [
    "print(prompt.format(input=\"I want to swap 100 DAI to USDC on UniSwap\"))\n",
    "chain = create_extraction_chain(llm, schema)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
